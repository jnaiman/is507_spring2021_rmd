---
title: "Intro to Numerical Data, Continuing Intro to R"
include_overview: true
week: 2
readings:
 - This weeks topics cover remaining parts of OIS 1.1, 1.2, 1.3, 2.1; OIS 1.4 & 2.3 (we won't cover 2.3 yet, but will cover the concepts presented here later in the class so feel free to read it over now).
 - We will also cover ITR 1, 2, 5, 6, 7, 12 (ITR can be skimmed or read in depth depending on comfort level with coding)
questions:
 - How can we analyze numerical data?
 - TBD
objectives:
 - TBD
keypoints:
 - "TBD"
source: Rmd
<!--latex_engine: xelatex-->
---



```{r setup, include=FALSE}
require("knitr")
#require("pandoc")
source("../bin/chunk-options.R")
source("../bin/functions.R")
library(tinytex)
```
<!-- JPN: attribution formatting -->
<style type="text/css" rel="stylesheet">
* {.attribution{
     position:absolute;
     bottom:0;
     right:0;
     font-size:0.5em
 }}
</style>

## Summary statistics and histograms with data in R

### Review

Last time we talked about some *summary statistics* and how to calculate them for data that is made up of numbers:
  * the *mean* is the sum of all data values divided by the number of data points
  * the *median* can be thought of as the "middle" number that splits the data into two halves if we order numerical data from smallest to largest
  * the *standard* deviaion is the square root of something called the *varience* which is roughly the average distnace of data values from the mean
  * the *first/third quartiles* delinate where 25% of the data falls below (first) and above (third) if we ordered the data from smallest to largest (the *median* is like the 50% or second quartile)

Let's do some analysis with "fake" class data showing programming histories of students in the class.

```{r d1p2}
classData = read.csv("data/formatted_class_answers.csv", stringsAsFactors=T)
# note: this is a placeholder for real data
```

Make sure this file is stored somewhere you can remember!  You can put it in the same directory as this file (or whatever R-script you are working from) or you can specify a location.  For example, on my Mac I can specify the default `Downloads` folder as the location with:

~~~
classData = read.csv("~/Downloads/formatted_class_answers.csv", stringsAsFactors=T)
~~~
{: .language-r}

What is in this dataset?

```{r d2p2}
classData
```

What are the names of the columns?
```{r cnp2}
colnames(classData)
```

Let's make a vector of the different languages folks use:
```{r lp2}
languages = classData[,3]
languages
```

We can also ask for the "levels" of these catagories:
```{r l2p2}
print(levels(languages))
```

Let's try making some plots of the language data.
```{r l3p3}
hist(languages) # should produce an error since "languages" is NOT a count - its a bunch of strings
```

Since `languages` is not numerical data, to make a histogram we have to play some tricks.  First, let's start by checking out the output of the `table` function:
```{r l4p3}
table(languages) # shows how many "hits" for a specific language
```

We can try using the `hist` function again:
```{r l4p2}
hist(table(languages)) # plots something now, but is actually counting # of bottom level, not counts
```

Not quite what we want, so let's try another plotting function called `barplot`:
```{r lh1p2}
barplot(table(languages)) # which sort of does what we want
```

Note: there are some long strings that aren't showing we can try changing one - for example, "python" should be "Python":
```{r lh2p2}
print(levels(languages))
```

We can fix this issue with some clever renaming of our levels:
```{r lh3p2}
print(levels(languages)[4]) # let's replace this
```
```{r lh4p2}
levels(languages)[4] = "Python" # with this
```

Take a look:
```{r lh5p2}
levels(languages)
```

Let's try replotting:
```{r lh6p2}
barplot(table(languages))
```

But what is the y axis?
```{r lh7p2}
barplot(table(languages),ylab='Counts')
```

<!-- JPN: note you need double dollar signs for latex here -->
Ok, but for many languages this can be hard to see $$\rightarrow$$ maybe different colors for each?
```{r lh8p2}
barplot(table(languages),ylab='Counts',col=c("red","blue","green","yellow","magenta"))
```

Ok cool, we see that a lot of folks use Python.

We can do the same sort of thing for the length of time folks have been coding:

```{r lh9p2}
time_in = classData[,4]
barplot(table(time_in)) 
```
Note: In RStudio, you'll have to expand the window to see all the labels.

Ok, so this tells us *something* but its hard to get a sense of the actual timescales since they are not ordered & are non-uniform increments of time.

Additionally, things are "out of order" because they don't fall in nice ordered time bins.  This is because this data is stored as "categorical" data, i.e. in this case as strings:
```{r ll1p2}
levels(time_in)
```

## Practicing for-loops and if-else statements

Let's reformat this data a bit and get some practice with for-loops in R in the process!

```{r f1p2}
time_min = c() # storage, save the min edge of our bins in years
time_max = c() # storage, save the max edge of our bins in years
```

Let's look at the options again:
```{r f2p2}
myLevels = levels(time_in)
print(myLevels)
```

Now we get to practice doing a for-loop in R.  Note, it is similar to how it's done in Python, but there are a few differences!  The syntax is generally:

~~~
for (loop_index in 1:Number_of_loops){
   # DO STUFF
}
~~~
{: .language-r}

Note that this definition includes `{}` instead of indentations to denote what is contained in the for-loop.  (if-statements are denoted similary as we'll see below.)

Let's do a for loop and determine bins by hand:
```{r f3p2}
for (i in 1:length(time_in)){
  if (time_in[i] == "< 6 months"){ # < 6 months
    time_min = c(time_min,0)
    time_max = c(time_max, 0.5) # in years => 0.5 years = 6 months
  } else if (time_in[i] == "Between 6 months to 1 year") { # 0.5-1 years
    time_min = c(time_min, 0.5)
    time_max = c(time_max, 1.0)
  } else if (time_in[i] == "1-2 years") { # 1-2 years
    time_min = c(time_min, 1.0)
    time_max = c(time_max, 2.0)
  } else if (time_in[i] == "2-4 years") { # 2-4 years
    time_min = c(time_min, 2.0)
    time_max = c(time_max, 4.0)
  } else { # otherwise, >4 years
    time_min = c(time_min,4.0) 
    time_max = c(time_max,5.0) # just giving an arbitrary upper bound of 5 years
  }
}
```

```{r f4p2}
print(time_min)
print(time_max)
```

Let's say the mid-point of this data is the `time`:
```{r f5p2}
time = 0.5*(time_min+time_max)
hist(time)
```

Note of course, in reality, the bins are not the same size so we can manually change the break-points to more accurately represent the data:
```{r f6p2}
hist(time,breaks=c(0.0,0.5,1,2,4,5))
```

Hmmm, but that looks like density, not counts, how do we get counts?
~~~
help(hist)
~~~
{: .language-r}
> ```{r lhelp22, echo = FALSE, results = "asis"}
> tmp <- tempfile()
> static_help("graphics", "hist", tmp)
> out <- readLines(tmp)
> headfoot <- grep("body>", out)
> cat(out[(headfoot[1] + 1):(headfoot[2] - 1)], sep = "\n")
> ```

See there is a "freq" variable, set to `TRUE` to get counts:
```{r f7p2}
hist(time,breaks=c(0.0,0.5,1,2,4,5),freq=TRUE)
```

We get an error telling us that the areas are wrong, but we have to think about what that means for us $$\rightarrow$$ do we actually care?  Density is telling us the frequency over the unit time, but thats not what we really want $$\rightarrow$$ we want counts with bars representing actual times.

Picking which one depends on your data & how you want to present it and you have to make sure to think about it.

## Summary statistics for class data

Let's look at some summary stats for our data for how long folks have been programming:
```{r f8p2}
summary(time)
```

Let's over plot where these are on our histograms using another plotting function called `abline` that overplots lines on our plots:
```{r f9p2, warning=FALSE}
hist(time,breaks=c(0.0,0.5,1,2,4,5),freq=TRUE)

abline(v = mean(time), col = "blue", lwd = 2)
abline(v = median(time), col = "red", lwd = 2)
```

Let's also add a legend:
```{r f10p2, warning=FALSE}
hist(time,breaks=c(0.0,0.5,1,2,4,5),freq=TRUE)

abline(v = mean(time), col = "blue", lwd = 2)
abline(v = median(time), col = "red", lwd = 2)

legend("topright",c("Mean","Median"),col=c("blue","red"),lwd=2)
```

Something to think about - does the mean or median describe the distribution better here?  What do they mean if the box sizes are different?  Keep this thoughts with you over the next few classes.

Now let's say we add the data of an old person in like myself that has been programming for a bit:
```{r nt1p2}
new_time = c(time,18.0)
```

Let's overplot the mean and median of our new time on our old histogram:
```{r nt2p2, warning=FALSE}
# old plot
hist(time,breaks=c(0.0,0.5,1,2,4,5),freq=TRUE)
abline(v = mean(time), col = "blue", lwd = 2)
abline(v = median(time), col = "red", lwd = 2)
legend("topright",c("Mean","Median"),col=c("blue","red"),lwd=2)

# new additions
abline(v=mean(new_time),col="blue",lwd=4,lty=2)
abline(v=median(new_time),col="red",lwd=4,lty=2)
```

We see that the mean changes a lot, BUT the median does not $\rightarrow$ this is very interesting to think about when we want to characterize our data.

Let's try the same exercise with the standdard deviation and the interquartile range (IQR).  This time we'll try making some lines on our plot using the `lines` function instead of `abline` for some variety, first with our original dataset:
```{r nt3p2, warning=FALSE}
hist(time,breaks=c(0.0,0.5,1,2,4,5),freq=TRUE)

#  Usually (and later on in class) we'll talk about full STDDEV's around the mean, 
#    but 1/2 STDDEV is a little easier to see here
lines(c(mean(time)-0.5*sd(time),mean(time)+0.5*sd(time)),c(2,2), col="blue",lwd=2)
# lets add the 25th & 75th quantiles
lines(c(median(time)-0.5*IQR(time),median(time)+0.5*IQR(time)), c(1.5,1.5), col="red",lwd=2)

# again, lets add a little legend
legend("topright",c("STDDEV","Quartiles"),col=c("blue","red"),lwd=2)
```

And let's see how both of these change with adding my data point:
```{r nt4p2, warning=FALSE}
# Old plot
hist(time,breaks=c(0.0,0.5,1,2,4,5),freq=TRUE)
lines(c(mean(time)-0.5*sd(time),mean(time)+0.5*sd(time)),c(2,2), col="blue",lwd=2)
lines(c(median(time)-0.5*IQR(time),median(time)+0.5*IQR(time)), c(1.5,1.5), col="red",lwd=2)
legend("topright",c("STDDEV","Quartiles"),col=c("blue","red"),lwd=2)

# new points
lines(c(mean(new_time)-0.5*sd(new_time),mean(new_time)+0.5*sd(new_time)),
      c(2,2), col="blue",lwd=4, lty=2)
lines(c(median(new_time)-0.5*IQR(new_time),median(new_time)+0.5*IQR(new_time)), 
      c(1.5,1.5), col="red",lwd=2,lty=2)
```

So, we also see that while the standdard deviation changes a lot with new and very different data, the quantiles do not (as much) -- also something interesting to consider in characterizing data!

## A few more things we can do with data

In RStudio, there a few helpful things you can try, like:

~~~
View(classData)
~~~
{: .language-r}

Or double clicking on "classData" in the "Global Environment" panel.

We can make a dotchart of the programming time range:
```{r dc1p2}
dotchart(time,xlab="Programming Age")
```
We can sort of see that there are a lot of dots $\lesssim$ 1 year, and a few at 3 years.

Note here: y-axis means nothing for dotcharts.

Can also see that in a boxplot:
```{r bp1p2}
boxplot(time)
```

Note: we would usually have whiskers at the tops *and* bottoms but this can be different for different distributions.

Maybe lets remind ourselves of what we are plotting:
```{r bp2p2}
boxplot(time,ylab="Programming Age")
```

For this last one, lets also overlay the boxplot for newtime too:
```{r bp3p2}
boxplot(time,new_time, col=c("green","purple"))
```
... and lets add a little legend too:
```{r bp4p2}
boxplot(time,new_time, col=c("green","purple"))
legend("topleft",c("Programming Age","New Programming Age"),fill=c("green","purple"))
```

Now we can see that again - the boxplots don't change a huge amount, only the new age one now includes an outlier point for my old-person programming age.

There are also a bunch of parameters you can change with boxplots we aren't going to get into here.

<style>
.mySlides1p2 {display: "none"}
</style>

<div class="slideshow-container">

  <!-- Full-width images with number and caption text -->
  <div class="mySlides1p2" >
    <div class="numbertext">1 / 3</div>
    <embed src="../lectureSlides/week01/slide1.pdf#toolbar=0&navpanes=0&scrollbar=0"/>
    <div class="text">Some of these may look familar but some might be new -- the mean, median and quartiles might be new.</div>
  </div>

  <div class="mySlides1p2">
    <div class="numbertext">2 / 3</div>
    <embed src="../lectureSlides/week01/slide2.pdf#toolbar=0&navpanes=0&scrollbar=0" />
    <div class="text">Mean and Median represent the typical value of your numerical dataset.</div>
  </div>
  
  <div class="mySlides1p2">
    <div class="numbertext">3 / 3</div>
    <embed src="../lectureSlides/week01/slide3.pdf#toolbar=0&navpanes=0&scrollbar=0" />
    <div class="text">Standard deviation and quartiles give measures of the variability in the data.</div>
  </div>

  <!-- Next and previous buttons -->
  <a class="prev" onclick="showSlidesLib.plusSlides(-1,0)">&#10094;</a>
  <a class="next" onclick="showSlidesLib.plusSlides(1,0)">&#10095;</a>
</div>
<br>


<!-- Actually run the script -->
<script type="text/javascript" src="../assets/js/showslideinit.js"></script>
<script type="text/javascript">
var slideIndex = [1];
var slideId = ['mySlides1p2'];
showSlidesLib.init([slideIndex, slideId, 1, 0]); //, 1, "controlId"]);
showSlidesLib.showSlidesInitial();
//showSlidesLib.showSlides(1,0);
</script>

<!--<script src="../assets/js/slideshow.js"></script>-->
